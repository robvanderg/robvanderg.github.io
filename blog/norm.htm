
<!DOCTYPE html>
<html lang="en">
    <head>
         <meta charset="UTF-8">
         <title>Rob van der Goot</title>
         <link rel="stylesheet" media="screen and (min-width: 1000px)" href="../css/big.css" />
         <link rel="stylesheet" media="screen and (max-width: 1000px)" href="../css/small.css"/>
        <link rel="icon" href="../favicon.ico" type="image/x-icon" />
     </head>
     <body>
         <div id="wrapper">
             <div id="menu">
                <div id="menuText">
                Menu
                </div>
                 <div id="buttonWrapper">
                     <a class="button" href="../">Home</a>
                     <a class="button" href="../papers/">Papers</a>
                     <a class="button" href="../cv/">CV</a>
                     <a class="button" href="../datasets/">Datasets</a>
                     <a class="button" href="../demos/">Demos</a>
                     <a class="button" href="../blog/">Blog</a>
                     <a class="button" href="../thesisProjects/">Thesis Projects</a>
                 </div>
             </div>
             <div id="content">

<h2>Normalization datasets</h2>
<p>In the MultiLexNorm shared task (WNUT 2021), we made a first attempt at
homogenising multiple lexical normalization datasets in a variety of languages
into one standard.  This project was started to improve the evaluation and
comparison of existing lexical normalization models, as well as pushing the
focus to a larger variety of languages. We defined lexical normalization as the
task of "transforming an utterance into its standard form, word by word,
including both one-to-many (1-n) and many-to-one (n-1) replacements." An
example of an utterance annotated for this task would be:</p>

<table>
  <tr>
    <th>most</th>
    <th>social</th>
    <th>pple</th>
    <th>r</th>
    <th>troublsome</th>
  </tr>
  <tr>
    <td>most</td>
    <td>social</td>
    <td>people</td>
    <td>are</td>
    <td>troublesome</td>
  </tr>
</table>

<p>More examples and information about MultiLexNorm can be found on the <a
href="http://noisy-text.github.io/2021/multi-lexnorm.html">task website</a> and
<a href="http://noisy-text.github.io/2021/multi-lexnorm.html/">overview
paper</a>.</p>

<p>On this page, I collect references to datasets that were not included in
MultiLexNorm for a variety of reasons, some of these are word-based, not
publicly available/sharable, they include translation/transcription, or I only
found out about them after the shared task. Hopefully, the MultiLexNorm
benchmark will be expanded in the future with more varied languages. Note that
I focus on social media datasets here, there are also historical and medical
datasets for the lexical normalization task.</p>

<table>
  <tr>
    <th>Language</th>
    <th>Source</th>
    <th>Notes</th>
  </tr>
  <tr>
    <td>Bangla-English</td>
    <td><a href="https://ieeexplore.ieee.org/document/7232908">Dutta et al. (2015)</a></td>
    <td>Paper behind paywall</td>
  </tr>
  <tr>
    <td>Chinese (Mandarin)</td>
    <td><a href="https://aclanthology.org/D08-1108.pdf">Li & Yarowsky (2008)</a></td>
    <td>No context</td>
  </tr>
  <tr>
    <td>Chinese (Mandarin)</td>
    <td><a href="https://aclanthology.org/I13-1015v2.pdf">Wang et al. (2013)</a></td>
    <td>No context</td>
  </tr>
  <tr>
    <td>Danish</td>
    <td><a href="https://openreview.net/pdf?id=OAL36C-9qfE">Hansen et al. (2023)</a></td>
    <td>Not public, after shared task</td>
  </tr>
  <tr>
    <td>Flemish</td>
    <td><a href="https://aclanthology.org/R13-1024.pdf">De Clercq et al. (2013)</a></td>
    <td>Not public, includes translation (to Dutch)</td>
  </tr>
  <tr>
    <td>Finnish</td>
    <td><a href="https://helda.helsinki.fi/bitstream/handle/10138/344932/Vehomaki_Varpu_thesis_2022.pdf">Vehom√§ki (2022)</a></td>
    <td>After MultiLexNorm</td>
  </tr>
  <tr>
    <td>Greek</td>
    <td><a href="https://www.diva-portal.org/smash/get/diva2:1499642/FULLTEXT01.pdf">Toska (2020)</a></td>
    <td></td>
  </tr>
  <tr>
    <td>Hindi-English</td>
    <td><a href="https://aclanthology.org/N18-1090.pdf">Bhat et al. (2018)</a></td>
    <td>Includes transcription</td>
  </tr>
  <tr>
    <td>Hindi-English</td>
    <td><a href="https://aclanthology.org/2020.coling-industry.13.pdf">Makhija et al. (2020)</a></td>
    <td></td>
  </tr>
  <tr>
    <td>Indonesian</td>
    <td><a href="https://colips.org/conferences/ialp2020/proceedings/papers/IALP2020_P32.pdf">Kurnia & Yulianti (2020)</a></td>
    <td>There seems to be no word allignment</td>
  </tr>
  <tr>
    <td>Irish</td>
    <td><a href=""https://aclanthology.org/2022.acl-long.473.pdf>Cassidy et al. (2022)</a></td>
    <td></td>
  </tr>
  <tr>
    <td>Japanese</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Kazakh</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Latvian</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Malaysian</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Portuguese</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Russian-Kazakh</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Urdu</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Uyghur</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Vietnamese</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
  <tr>
    <td>Singlish</td>
    <td><a href=""></a></td>
    <td></td>
  </tr>
</table>

Note: Turkish and English datasets not in MultiLexNorm are not listed here yet.




            </div>
        </div>
    </body>
</html>

